---
date: 2021-03-02T02:50:00.000Z
layout: post
title: Learning Curve Theory
subtitle: Determine to which extent power laws are universal or depend on the data distribution or loss function.
description: Determine to which extent power laws are universal or depend on the data distribution or loss function.
image: https://res.cloudinary.com/dthouk4zq/image/upload/v1614844755/pd_x750_macbook_air_13-pad_1000x1000_f8f8f8.u4_tzfmsm.jpg
optimized_image: https://res.cloudinary.com/dthouk4zq/image/upload/c_limit,h_200,w_380/v1614844755/pd_x750_macbook_air_13-pad_1000x1000_f8f8f8.u4_tzfmsm.jpg
category: Machine Learning Theory
tags:
  - Machine Learning Theory
  - Massive AI
  - Deep Learning Theory
author: Kyuyong-Shin
---
### Description
Recently a number of empirical “universal” scaling law papers have been published, most notably by Open AI. But, theoretical understanding of this phenomenon is largely lacking. This paper develops and theoretically analyse the simplest possible (toy) model that can exhibit n^-β learning curves for arbitrary power β > 0, and determine to which extent power laws are universal or depend on the data distribution or loss function.

### Video
<iframe width="560" height="315" src="https://www.youtube.com/embed/scjEr5_CEXU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### References
[Learning Curve Theory](http://www.hutter1.net/publ/scaling.pdf)
