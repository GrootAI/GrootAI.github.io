---
date: 2020-12-21T01:50:00.000Z
layout: post
title: Scaling Laws for Neural Language Models
subtitle: Get the empirical scaling laws for language model performance on the cross-entropy loss.
description: Get the empirical scaling laws for language model performance on the cross-entropy loss.
optimized_image: https://res.cloudinary.com/dfnkx5mr1/image/upload/c_limit,h_200,w_380/v1609604334/post_img/1_Ru8S_DMZv9ipDZVKKNL_4A_nib9st.jpg
category: Deep Learning Theory
tags:
  - Deep Learning Theory
  - Massive AI
  - NLP
author: Kyuyong-Shin
---

### Video
<iframe width="560" height="315" src="https://www.youtube.com/embed/a3Ga_Q98L9M" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### References
[Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)
